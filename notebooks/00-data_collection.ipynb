{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ffb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# 00 - Data Collection\n",
    "#\n",
    "# This notebook handles reading the raw CSVs, validating them, saving copies to `data/raw/`,\n",
    "# and creating a simple data dictionary and sample rows for inspection.\n",
    "#\n",
    "# It references the project specification PDF located at:\n",
    "# `/mnt/data/2792ae81-88dc-4749-89fb-adeaa7054a3d.pdf`\n",
    "#\n",
    "# Usage:\n",
    "# - Place `application_record.csv` and `credit_record.csv` in the project root or upload them.\n",
    "# - Run cells sequentially.\n",
    "\n",
    "# %%\n",
    "# Standard imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path('.').resolve()\n",
    "RAW_DIR = PROJECT_ROOT / 'data' / 'raw'\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS_DIR = PROJECT_ROOT / 'reports' / 'figures'\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Spec PDF path (uploaded spec)\n",
    "SPEC_PDF_PATH = '/mnt/data/2792ae81-88dc-4749-89fb-adeaa7054a3d.pdf'\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Spec PDF: {SPEC_PDF_PATH}\")\n",
    "print(f\"Raw data directory: {RAW_DIR}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# Cell: Helper functions\n",
    "# - save_dataframe_sample: saves a CSV sample for quick viewing\n",
    "# - create_data_dictionary: builds a very small data dictionary from a dataframe\n",
    "\n",
    "# %%\n",
    "\n",
    "def save_dataframe_sample(df: pd.DataFrame, dest: Path, name: str, n: int = 5):\n",
    "    dest.mkdir(parents=True, exist_ok=True)\n",
    "    sample_path = dest / f\"{name}_sample.csv\"\n",
    "    df.head(n).to_csv(sample_path, index=False)\n",
    "    print(f\"Saved sample to: {sample_path}\")\n",
    "    return sample_path\n",
    "\n",
    "\n",
    "def create_data_dictionary(df: pd.DataFrame, dest: Path, name: str):\n",
    "    \"\"\"Create a simple data dictionary with column, dtype, non-null count, unique sample values.\"\"\"\n",
    "    meta = []\n",
    "    for col in df.columns:\n",
    "        dtype = str(df[col].dtype)\n",
    "        non_null = int(df[col].notnull().sum())\n",
    "        unique_vals = df[col].dropna().unique()[:5].tolist()\n",
    "        meta.append({\n",
    "            'column': col,\n",
    "            'dtype': dtype,\n",
    "            'non_null': non_null,\n",
    "            'sample_values': json.dumps(unique_vals, default=str)\n",
    "        })\n",
    "    dd = pd.DataFrame(meta)\n",
    "    dest.mkdir(parents=True, exist_ok=True)\n",
    "    dd_path = dest / f\"{name}_data_dictionary.csv\"\n",
    "    dd.to_csv(dd_path, index=False)\n",
    "    print(f\"Saved data dictionary to: {dd_path}\")\n",
    "    return dd_path\n",
    "\n",
    "# %% [markdown]\n",
    "# Cell: Load raw files (attempt to read common locations)\n",
    "# - Looks for files in project root and in /mnt/data (where uploaded files often appear)\n",
    "\n",
    "# %%\n",
    "# Candidate filenames\n",
    "app_fnames = ['application_record.csv', 'application_record.csv.gz']\n",
    "credit_fnames = ['credit_record.csv', 'credit_record.csv.gz']\n",
    "\n",
    "# Candidate dirs\n",
    "candidate_dirs = [PROJECT_ROOT, Path('/mnt/data'), RAW_DIR]\n",
    "\n",
    "found_app = None\n",
    "found_credit = None\n",
    "for d in candidate_dirs:\n",
    "    for fn in app_fnames:\n",
    "        p = d / fn\n",
    "        if p.exists():\n",
    "            found_app = p\n",
    "            break\n",
    "    for fn in credit_fnames:\n",
    "        p = d / fn\n",
    "        if p.exists():\n",
    "            found_credit = p\n",
    "            break\n",
    "\n",
    "print('Found application file:', found_app)\n",
    "print('Found credit file:', found_credit)\n",
    "\n",
    "if found_app is None or found_credit is None:\n",
    "    raise FileNotFoundError(\n",
    "        'Could not find both application_record.csv and credit_record.csv in project root or /mnt/data.\\n'\n",
    "        'Please upload them to the workspace or place them in the project root.'\n",
    "    )\n",
    "\n",
    "# Read files\n",
    "print('Reading application_record...')\n",
    "df_app = pd.read_csv(found_app)\n",
    "print('Reading credit_record...')\n",
    "df_credit = pd.read_csv(found_credit)\n",
    "\n",
    "print('\\napplication_record shape:', df_app.shape)\n",
    "print('credit_record shape:', df_credit.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# Cell: Save raw copies into `data/raw/` (keeps originals intact)\n",
    "\n",
    "# %%\n",
    "app_dest = RAW_DIR / 'application_record.csv'\n",
    "credit_dest = RAW_DIR / 'credit_record.csv'\n",
    "\n",
    "# Only copy if different\n",
    "if found_app.resolve() != app_dest.resolve():\n",
    "    df_app.to_csv(app_dest, index=False)\n",
    "    print(f'Copied application_record to {app_dest}')\n",
    "else:\n",
    "    print('Application record already in raw directory')\n",
    "\n",
    "if found_credit.resolve() != credit_dest.resolve():\n",
    "    df_credit.to_csv(credit_dest, index=False)\n",
    "    print(f'Copied credit_record to {credit_dest}')\n",
    "else:\n",
    "    print('Credit record already in raw directory')\n",
    "\n",
    "# %% [markdown]\n",
    "# Cell: Quick validation checks\n",
    "# - Check for common ID columns present in both datasets\n",
    "# - Check for STATUS column in credit_record (required for label creation)\n",
    "\n",
    "# %%\n",
    "possible_id_cols = ['ID', 'id', 'client_id', 'Client_id', 'application_id', 'applicationId']\n",
    "common_cols = set(df_app.columns).intersection(set(df_credit.columns))\n",
    "print('Common columns between app & credit:', common_cols)\n",
    "\n",
    "inferred_id = None\n",
    "for c in possible_id_cols:\n",
    "    if c in df_app.columns and c in df_credit.columns:\n",
    "        inferred_id = c\n",
    "        break\n",
    "\n",
    "if inferred_id is None:\n",
    "    # if exactly one common column exists, use it\n",
    "    if len(common_cols) == 1:\n",
    "        inferred_id = list(common_cols)[0]\n",
    "        print(f\"Inferred ID column as the single common column: {inferred_id}\")\n",
    "    else:\n",
    "        print('\\nCould not unambiguously infer an ID column.\\n')\n",
    "        print('Please check the column names and set the ID column manually in the next cell.')\n",
    "\n",
    "print('Inferred ID column:', inferred_id)\n",
    "\n",
    "# STATUS check\n",
    "if 'STATUS' not in df_credit.columns:\n",
    "    print('WARNING: STATUS column not found in credit_record. Label creation will fail until this is resolved.')\n",
    "else:\n",
    "    print('STATUS column found in credit_record.')\n",
    "\n",
    "# %% [markdown]\n",
    "# Cell: Save sample rows and data dictionaries for both tables\n",
    "\n",
    "# %%\n",
    "save_dataframe_sample(df_app, RAW_DIR, 'application_record', n=10)\n",
    "save_dataframe_sample(df_credit, RAW_DIR, 'credit_record', n=10)\n",
    "create_data_dictionary(df_app, RAW_DIR, 'application_record')\n",
    "create_data_dictionary(df_credit, RAW_DIR, 'credit_record')\n",
    "\n",
    "# %% [markdown]\n",
    "# Cell: Summary & next steps\n",
    "# - We have copied raw CSVs to `data/raw/`.\n",
    "# - Review the inferred ID column above. If it's incorrect, set `INFERRED_ID = '<your_id_col>'` below and re-run the merge notebook.\n",
    "# - Next: run `01-merge_and_label.ipynb` which will create the label and merged dataset at `/data/processed/merged.csv`.\n",
    "\n",
    "# %%\n",
    "# If you need to override the inferred ID, set it here and save for the next notebook\n",
    "INFERRED_ID = inferred_id\n",
    "print('Set INFERRED_ID for downstream notebooks:', INFERRED_ID)\n",
    "\n",
    "# Save a small metadata JSON for the pipeline to read\n",
    "meta = {\n",
    "    'spec_pdf': SPEC_PDF_PATH,\n",
    "    'inferred_id': INFERRED_ID,\n",
    "    'raw_app_path': str(app_dest),\n",
    "    'raw_credit_path': str(credit_dest)\n",
    "}\n",
    "\n",
    "meta_path = PROJECT_ROOT / 'data' / 'raw' / 'metadata.json'\n",
    "with open(meta_path, 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(f'Saved metadata to {meta_path}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
